{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17f340a6-d62c-4606-936f-81b442daa66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping reviews for: Samsung Galaxy S23 (Product ID: MOBGNPGZVX4PCTTF)\n",
      "Scraping page 1...\n",
      "Scraping page 2...\n",
      "Scraping page 3...\n",
      "Scraping page 4...\n",
      "Scraping page 5...\n",
      "Scraping page 6...\n",
      "Scraping page 7...\n",
      "Scraping page 8...\n",
      "Scraping page 9...\n",
      "Scraping page 10...\n",
      "Scraping page 11...\n",
      "Scraping page 12...\n",
      "Scraping page 13...\n",
      "Scraping page 14...\n",
      "No more reviews found for Samsung Galaxy S23 or page structure changed.\n",
      "Scraping reviews for: Vivo T3 (Product ID: MOBH4EACZ7SACMMM)\n",
      "Scraping page 1...\n",
      "Scraping page 2...\n",
      "Scraping page 3...\n",
      "Scraping page 4...\n",
      "Scraping page 5...\n",
      "Scraping page 6...\n",
      "Scraping page 7...\n",
      "Scraping page 8...\n",
      "Scraping page 9...\n",
      "Scraping page 10...\n",
      "Scraping page 11...\n",
      "No more reviews found for Vivo T3 or page structure changed.\n",
      "Scraping reviews for: Google Pixel 8 (Product ID: MOBGT5F2WD8HPTPZ)\n",
      "Scraping page 1...\n",
      "Scraping page 2...\n",
      "Scraping page 3...\n",
      "Scraping page 4...\n",
      "Scraping page 5...\n",
      "Scraping page 6...\n",
      "Scraping page 7...\n",
      "Scraping page 8...\n",
      "Scraping page 9...\n",
      "Scraping page 10...\n",
      "Scraping page 11...\n",
      "Scraping page 12...\n",
      "Scraping page 13...\n",
      "Scraping page 14...\n",
      "Scraping page 15...\n",
      "Scraping page 16...\n",
      "Scraping page 17...\n",
      "Scraping page 18...\n",
      "Scraping page 19...\n",
      "Scraping page 20...\n",
      "Scraping page 21...\n",
      "No more reviews found for Google Pixel 8 or page structure changed.\n",
      "Scraping reviews for: Motorola Edge 50 (Product ID: MOBHFHDRVUDB3HFX)\n",
      "Scraping page 1...\n",
      "Scraping page 2...\n",
      "Scraping page 3...\n",
      "Scraping page 4...\n",
      "Scraping page 5...\n",
      "Scraping page 6...\n",
      "Scraping page 7...\n",
      "Scraping page 8...\n",
      "Scraping page 9...\n",
      "Scraping page 10...\n",
      "Scraping page 11...\n",
      "No more reviews found for Motorola Edge 50 or page structure changed.\n",
      "Scraping reviews for: Realme 12 Pro (Product ID: MOBGYQ6BVDHRJRSG)\n",
      "Scraping page 1...\n",
      "Scraping page 2...\n",
      "Scraping page 3...\n",
      "Scraping page 4...\n",
      "Scraping page 5...\n",
      "Scraping page 6...\n",
      "Scraping page 7...\n",
      "Scraping page 8...\n",
      "Scraping page 9...\n",
      "Scraping page 10...\n",
      "Scraping page 11...\n",
      "No more reviews found for Realme 12 Pro or page structure changed.\n",
      "All reviews saved to 'combined_flipkart_phone_reviews.csv'.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import pandas as pd\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "\n",
    "# Set up Chrome options\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")  # Run in headless mode\n",
    "options.add_argument(\"--no-sandbox\")\n",
    "options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "# Specify the path to your locally installed chromedriver\n",
    "chromedriver_path = r'C:\\New folder\\chromedriver-win64\\chromedriver.exe'  # Update this path\n",
    "driver = webdriver.Chrome(service=Service(chromedriver_path), options=options)\n",
    "\n",
    "# List of URLs for different phones\n",
    "phone_urls = {\n",
    "    \"Samsung Galaxy S23\": \"https://www.flipkart.com/samsung-galaxy-s23-5g-phantom-black-128-gb/product-reviews/itm1f3efe01d1c61?pid=MOBGNPGZVX4PCTTF&lid=LSTMOBGNPGZVX4PCTTFYWYWBL&marketplace=FLIPKART\",\n",
    "    \"Vivo T3\": \"https://www.flipkart.com/vivo-t3-ultra-frost-green-256-gb/product-reviews/itme360ff5b7dbab?pid=MOBH4EACZ7SACMMM&lid=LSTMOBH4EACZ7SACMMMMVZG93&marketplace=FLIPKART\",\n",
    "    \"Google Pixel 8\": \"https://www.flipkart.com/google-pixel-8-hazel-128-gb/product-reviews/itm67e2a2531aaac?pid=MOBGT5F2WD8HPTPZ&lid=LSTMOBGT5F2WD8HPTPZ4A9QHI&marketplace=FLIPKART\",\n",
    "    \"Motorola Edge 50\": \"https://www.flipkart.com/motorola-edge-50-neo-pantone-grisaille-256-gb/product-reviews/itm5b85defa76389?pid=MOBHFHDRVUDB3HFX&lid=LSTMOBHFHDRVUDB3HFXLMEVTW&marketplace=FLIPKART\",\n",
    "    \"Realme 12 Pro\": \"https://www.flipkart.com/realme-12-pro-5g-navigator-beige-256-gb/product-reviews/itmcc78f150eeabd?pid=MOBGYQ6BVDHRJRSG&lid=LSTMOBGYQ6BVDHRJRSGDKJZZD&marketplace=FLIPKART\"\n",
    "}\n",
    "\n",
    "def fetch_html(url):\n",
    "    \"\"\"Fetch the HTML content of a given URL.\"\"\"\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(2)  # Allow time for the page to load\n",
    "        return BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching the page: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def extract_reviews(soup):\n",
    "    \"\"\"Extract reviews from the parsed HTML page.\"\"\"\n",
    "    reviews = []\n",
    "    if not soup:\n",
    "        return reviews  # Return empty list if no content\n",
    "\n",
    "    review_blocks = soup.find_all('div', {'class': 'cPHDOP col-12-12'})  # Updated class if structure changes\n",
    "    for block in review_blocks:\n",
    "        try:\n",
    "            rating_elem = block.find('div', {'class': 'XQDdHH Ga3i8K'})\n",
    "            review_elem = block.find('div', {'class': 'ZmyHeo'})\n",
    "            \n",
    "            \n",
    "            if rating_elem and review_elem:\n",
    "                review = {\n",
    "                    'Rating': rating_elem.text.strip(),\n",
    "                    'Review': review_elem.text.strip().replace('READ MORE', ''),\n",
    "                    \n",
    "                }\n",
    "                reviews.append(review)\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing a review block: {e}\")\n",
    "    return reviews\n",
    "def extract_product_id(url):\n",
    "    \"\"\"Extract the product ID from the Flipkart URL.\"\"\"\n",
    "    parsed_url = urlparse(url)\n",
    "    product_id = parse_qs(parsed_url.query).get('pid', [None])[0]\n",
    "    return product_id\n",
    "\n",
    "# Function to scrape reviews for a single phone\n",
    "def scrape_reviews_for_phone(phone_name, phone_url):\n",
    "    reviews = []\n",
    "    product_id = extract_product_id(phone_url)\n",
    "    page = 1\n",
    "    print(f\"Scraping reviews for: {phone_name} (Product ID: {product_id})\")\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            page_url = f\"{phone_url}&page={page}\"\n",
    "            print(f\"Scraping page {page}...\")\n",
    "            soup = fetch_html(page_url)\n",
    "            page_reviews = extract_reviews(soup)\n",
    "            if not page_reviews:\n",
    "                print(f\"No more reviews found for {phone_name} or page structure changed.\")\n",
    "                break\n",
    "            for review_data in page_reviews:\n",
    "                # Add product ID and phone name to each review entry\n",
    "                review_data['Product ID'] = product_id\n",
    "                review_data['Phone Name'] = phone_name\n",
    "            reviews.extend(page_reviews)\n",
    "            page += 1\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during scraping for {phone_name}: {e}\")\n",
    "    return reviews\n",
    "\n",
    "# List to hold all reviews from all phones\n",
    "all_reviews = []\n",
    "\n",
    "# Loop through each phone and scrape reviews\n",
    "for phone_name, phone_url in phone_urls.items():\n",
    "    phone_reviews = scrape_reviews_for_phone(phone_name, phone_url)\n",
    "    all_reviews.extend(phone_reviews)\n",
    "\n",
    "# Close the WebDriver after scraping all phones\n",
    "driver.quit()\n",
    "\n",
    "# Save all reviews into a single CSV file\n",
    "if all_reviews:\n",
    "    df = pd.DataFrame(all_reviews, columns=['Product ID', 'Phone Name', 'Rating', 'Review'])\n",
    "    df.to_csv(r'E:\\GUVI\\FINAL PROJECT\\combined_flipkart_phone_reviews.csv', index=False, encoding='utf-8')\n",
    "\n",
    "    print(\"All reviews saved to 'combined_flipkart_phone_reviews.csv'.\")\n",
    "else:\n",
    "    print(\"No reviews to save.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b16a347c-afcc-4959-8474-766c8142c905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.12.3 | packaged by conda-forge | (main, Apr 15 2024, 18:20:11) [MSC v.1938 64 bit (AMD64)]\n",
      "beautifulsoup4: 4.12.3\n",
      "selenium: 4.25.0\n",
      "pandas: 2.2.2\n",
      "textblob: 0.15.3\n",
      "transformers: 4.45.1\n",
      "streamlit: 1.32.0\n",
      "matplotlib: 3.8.4\n",
      "seaborn: 0.13.2\n"
     ]
    }
   ],
   "source": [
    "import pkg_resources\n",
    "import sys\n",
    "\n",
    "# List of packages to check, including Python\n",
    "packages = [\n",
    "    \"beautifulsoup4\",\n",
    "    \"selenium\",\n",
    "    \"pandas\",\n",
    "    \"textblob\",\n",
    "    \"transformers\",\n",
    "    \"streamlit\",\n",
    "    \"matplotlib\",\n",
    "    \"seaborn\",\n",
    "]\n",
    "\n",
    "# Check Python version\n",
    "print(f\"Python: {sys.version}\")\n",
    "\n",
    "# Check versions of specified packages\n",
    "for package in packages:\n",
    "    try:\n",
    "        version = pkg_resources.get_distribution(package).version\n",
    "        print(f\"{package}: {version}\")\n",
    "    except pkg_resources.DistributionNotFound:\n",
    "        print(f\"{package} is not installed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1387f504-2beb-4486-aee7-d9c841c3a191",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
